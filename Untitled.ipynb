{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9697b2d6",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bff06b8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5\n",
      "1       5\n",
      "2       3\n",
      "3       4\n",
      "4       5\n",
      "       ..\n",
      "3583    3\n",
      "3584    1\n",
      "3585    3\n",
      "3586    3\n",
      "3587    3\n",
      "Name: Score_5, Length: 3588, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(718, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv(\"Dataset/Dataset2.csv\")\n",
    "\n",
    "X = df.iloc[:,1:5]\n",
    "y = df.iloc[:,9]\n",
    "print(y)\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20, random_state=101)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01ca64e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. of Characters</th>\n",
       "      <th>No. of Words</th>\n",
       "      <th>No. of Unique words</th>\n",
       "      <th>POS Average</th>\n",
       "      <th>No. of Noun</th>\n",
       "      <th>No. of Adv</th>\n",
       "      <th>No. of Verb</th>\n",
       "      <th>No. of Adverb</th>\n",
       "      <th>Score_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No. of Characters</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.993885</td>\n",
       "      <td>0.808707</td>\n",
       "      <td>0.995065</td>\n",
       "      <td>0.980571</td>\n",
       "      <td>0.914136</td>\n",
       "      <td>0.968059</td>\n",
       "      <td>0.889886</td>\n",
       "      <td>0.882758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. of Words</th>\n",
       "      <td>0.993885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.794705</td>\n",
       "      <td>0.993824</td>\n",
       "      <td>0.967310</td>\n",
       "      <td>0.907233</td>\n",
       "      <td>0.980360</td>\n",
       "      <td>0.900120</td>\n",
       "      <td>0.878873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. of Unique words</th>\n",
       "      <td>0.808707</td>\n",
       "      <td>0.794705</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804533</td>\n",
       "      <td>0.825077</td>\n",
       "      <td>0.715943</td>\n",
       "      <td>0.757808</td>\n",
       "      <td>0.697219</td>\n",
       "      <td>0.805902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS Average</th>\n",
       "      <td>0.995065</td>\n",
       "      <td>0.993824</td>\n",
       "      <td>0.804533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977964</td>\n",
       "      <td>0.922356</td>\n",
       "      <td>0.977003</td>\n",
       "      <td>0.905625</td>\n",
       "      <td>0.875874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. of Noun</th>\n",
       "      <td>0.980571</td>\n",
       "      <td>0.967310</td>\n",
       "      <td>0.825077</td>\n",
       "      <td>0.977964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881704</td>\n",
       "      <td>0.925445</td>\n",
       "      <td>0.834518</td>\n",
       "      <td>0.868753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. of Adv</th>\n",
       "      <td>0.914136</td>\n",
       "      <td>0.907233</td>\n",
       "      <td>0.715943</td>\n",
       "      <td>0.922356</td>\n",
       "      <td>0.881704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877167</td>\n",
       "      <td>0.821531</td>\n",
       "      <td>0.800059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. of Verb</th>\n",
       "      <td>0.968059</td>\n",
       "      <td>0.980360</td>\n",
       "      <td>0.757808</td>\n",
       "      <td>0.977003</td>\n",
       "      <td>0.925445</td>\n",
       "      <td>0.877167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890448</td>\n",
       "      <td>0.849737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No. of Adverb</th>\n",
       "      <td>0.889886</td>\n",
       "      <td>0.900120</td>\n",
       "      <td>0.697219</td>\n",
       "      <td>0.905625</td>\n",
       "      <td>0.834518</td>\n",
       "      <td>0.821531</td>\n",
       "      <td>0.890448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.774481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score_5</th>\n",
       "      <td>0.882758</td>\n",
       "      <td>0.878873</td>\n",
       "      <td>0.805902</td>\n",
       "      <td>0.875874</td>\n",
       "      <td>0.868753</td>\n",
       "      <td>0.800059</td>\n",
       "      <td>0.849737</td>\n",
       "      <td>0.774481</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     No. of Characters  No. of Words  No. of Unique words  \\\n",
       "No. of Characters             1.000000      0.993885             0.808707   \n",
       "No. of Words                  0.993885      1.000000             0.794705   \n",
       "No. of Unique words           0.808707      0.794705             1.000000   \n",
       "POS Average                   0.995065      0.993824             0.804533   \n",
       "No. of Noun                   0.980571      0.967310             0.825077   \n",
       "No. of Adv                    0.914136      0.907233             0.715943   \n",
       "No. of Verb                   0.968059      0.980360             0.757808   \n",
       "No. of Adverb                 0.889886      0.900120             0.697219   \n",
       "Score_5                       0.882758      0.878873             0.805902   \n",
       "\n",
       "                     POS Average  No. of Noun  No. of Adv  No. of Verb  \\\n",
       "No. of Characters       0.995065     0.980571    0.914136     0.968059   \n",
       "No. of Words            0.993824     0.967310    0.907233     0.980360   \n",
       "No. of Unique words     0.804533     0.825077    0.715943     0.757808   \n",
       "POS Average             1.000000     0.977964    0.922356     0.977003   \n",
       "No. of Noun             0.977964     1.000000    0.881704     0.925445   \n",
       "No. of Adv              0.922356     0.881704    1.000000     0.877167   \n",
       "No. of Verb             0.977003     0.925445    0.877167     1.000000   \n",
       "No. of Adverb           0.905625     0.834518    0.821531     0.890448   \n",
       "Score_5                 0.875874     0.868753    0.800059     0.849737   \n",
       "\n",
       "                     No. of Adverb   Score_5  \n",
       "No. of Characters         0.889886  0.882758  \n",
       "No. of Words              0.900120  0.878873  \n",
       "No. of Unique words       0.697219  0.805902  \n",
       "POS Average               0.905625  0.875874  \n",
       "No. of Noun               0.834518  0.868753  \n",
       "No. of Adv                0.821531  0.800059  \n",
       "No. of Verb               0.890448  0.849737  \n",
       "No. of Adverb             1.000000  0.774481  \n",
       "Score_5                   0.774481  1.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27f8b055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC(probability=True)\n",
    "\n",
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d09c6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_pred = SVM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6033a015",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Polynomial Kernel):  89.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "poly_accuracy = accuracy_score(y_test, poly_pred)\n",
    "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4ee97",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f656ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 90.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors=13)\n",
    "KNN.fit(X_train,y_train)\n",
    "KNN_pred = KNN.predict(X_test)\n",
    "\n",
    "KNN_accuracy = accuracy_score(y_test,KNN_pred)\n",
    "print(\"KNN Accuracy:\", \"%.2f\" % (KNN_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52aaad",
   "metadata": {},
   "source": [
    "# RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e523fcd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Accuracy: 91.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(n_estimators=11,random_state =4)\n",
    "RFC.fit(X_train, y_train)\n",
    "RFC_pred = RFC.predict(X_test)\n",
    "\n",
    "RFC_accuracy = accuracy_score(y_test,RFC_pred)\n",
    "print(\"RFC Accuracy:\", \"%.2f\" % (RFC_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e812ca17",
   "metadata": {},
   "source": [
    "# XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7073ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rishavk\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:01:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB Accuracy: 92.20\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGB = XGBClassifier()\n",
    "XGB.fit(X_train, y_train)\n",
    "\n",
    "XGB_pred = XGB.predict(X_test)\n",
    "\n",
    "XGB_accuracy = accuracy_score(y_test,XGB_pred)\n",
    "print(\"XGB Accuracy:\", \"%.2f\" % (XGB_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72541b5f",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3abe6714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Accuracy: 90.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rishavk\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogisticRegression = LogisticRegression(solver='lbfgs',max_iter=9999999999999999999999999999999999999999999999999999999999999)\n",
    "LogisticRegression.fit(X_train, y_train)\n",
    "\n",
    "LogisticRegression_pred = LogisticRegression.predict(X_test)\n",
    "\n",
    "LogisticRegression_accuracy = accuracy_score(y_test,LogisticRegression_pred)\n",
    "print(\"LogisticRegression Accuracy:\", \"%.2f\" % (LogisticRegression_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32009d59",
   "metadata": {},
   "source": [
    "# Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb2706de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rishavk\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\users\\rishavk\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:01:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Stack Test Accuracy: 92.20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "estimator_list = [\n",
    "    ('rfc',RFC),\n",
    "    ('knn',KNN),\n",
    "    ('svm',SVM),\n",
    "    ('LR',LogisticRegression),\n",
    "    ('XGB',XGB)\n",
    "]\n",
    "\n",
    "# Build stack model\n",
    "stack_model = VotingClassifier(\n",
    "    estimators=estimator_list,voting='hard'\n",
    ")\n",
    "\n",
    "# Train stacked model\n",
    "stack_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "stack_pred = stack_model.predict(X_test)\n",
    "\n",
    "stack_accuracy = accuracy_score(y_test,stack_pred)\n",
    "print(\"Stack Test Accuracy:\", \"%.2f\" % (stack_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d58f481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkpUlEQVR4nO3deXxU1fnH8c8zSdh3UCAhFRS04AYVEMUFXABZBKs/wLrXilasYF0qarWiKO6K1VpQARUR6gYCKoqoIBZBRYUgO0oWQJBdBTJzfn9kTINAZkImOZnr9+3rvJg59849zxHmycm5595rzjlERKT8hXwHICLya6UELCLiiRKwiIgnSsAiIp4oAYuIeJJa1g10zDgtkMss5n63xHcIIoGTvyvHSnuM3RtWxp1z0hocWur2SqPME7CISLmKhH1HEDclYBEJFhfxHUHclIBFJFgiSsAiIl44jYBFRDwJ5/uOIG5KwCISLDoJJyLiiaYgREQ80Uk4ERE/dBJORMQXjYBFRDwJ7/YdQdyUgEUkWDQFISLiiaYgREQ8SaIRsO4HLCLBEonEX4phZplmNtPMssxskZkNitb/w8xyzGxBtHQv8pkhZrbczJaYWddYoWoELCKB4iIJOwmXD1zvnPvMzGoCn5rZO9FtjzjnHiy6s5m1AvoDRwLpwLtmdrhzbr+X5ikBi0iwJGgO2DmXB+RFX28zs8VARjEf6Q285JzbCawys+VAe+Dj/X0gqacgQqEQo9/+N/ePHQbAHY/fwvgPx/L8jGcY8tCNpKSmeI7wwI0a+RC52V+w4PMZvkNJuK5dOrFo4Yd8nTWbm24c6DuchAhinyBJ++UicRczG2Bm84uUAfs6pJk1BdoAc6NV15jZl2b2rJnVjdZlAGuKfCyb4hN2cifg//vT71m97NvC99Nfm8H5p1zCRadfTuUqlen1hx4eoyud556bSI+eF/gOI+FCoRAjHhtGz14XcvSxnenXrw8tW7bwHVapBLFPkMT9ioTjLs65kc65tkXKyF8ezsxqAK8Ag51zW4F/AYcBrSkYIT90oKHGTMBm9lsz+5uZjYiWv5lZywNtMFEOatyAE0/vwBvjpxXWffze3MLXixd8zcGNG/gILSFmzZ7L95s2+w4j4dq3a8OKFatZtepbdu/ezcSJkzi7V8xzFRVaEPsESdyvEoyAYzGzNAqS7zjn3KsAzrl1zrmwK7jmeRQF0wwAOUBmkY83idbtV7EJ2Mz+BrwEGPBJtBgw3sxujhl9GRp050CevPvfuH3M96SkptD13DOZO3Oeh8ikOOkZjViTnVv4Pjsnj/T0Rh4jKr0g9gmSuF+JWwVhwDPAYufcw0XqGxfZ7RxgYfT1ZKC/mVU2s2ZACwpy5n7FOgl3OXCkc26P04pm9jCwCBi+n8AHAAMADq19BI2qp8dopmROPKMDmzZsZslXy2hzwrF7bb/hnsF8MfdLvvjkq4S2KyJJIHE3ZO8IXAR8ZWYLonW3AOebWWvAAauBKwGcc4vMbCKQRcEKioHFrYCA2Ak4QsFyim9+Ud84um2fovMoI6FsHkt/TNujOKnLiZxw2vFUqlyJ6jWrcfuIIQy99l4uu+5i6tSvzS1/ejj2gaTc5easJbPJ/34gN8loTG7uWo8RlV4Q+wRJ3K/ErYKYTcFv/L80bR91P39mGDAs3jZiJeDBwAwzW8b/zu79BmgOXBNvI4n21PCneWr40wC0OeFYzr+qL0OvvZde53fn+E7tuLbf9TiX8LwvCTBv/gKaN29G06aZ5OSspW/f3lx0cZKcXd+PIPYJkrdfMQadFUqxCdg595aZHU7BJPPPyylygHmxhtY+3DD8OtZlr2Pk5H8C8MG0WYx+9HnPUR2YF55/glNPOYEGDeqxeuV87hz6IKPHvOQ7rFILh8MMGnwb06a+SEooxJixE8jKWuo7rFIJYp8gifuVRPeCsLIeKZbFFERFMPe7Jb5DEAmc/F05+/qVv0R+nPl03Dmnauc/lbq90tCVcCISLEk0AlYCFpFg0WPpRUQ8SaLbUSoBi0iwaApCRMQTJWAREU80BSEi4olOwomIeKIpCBERTzQFISLiiUbAIiKeKAGLiHiSRHdCVAIWkWDJ1yoIERE/dBJORMQTzQGLiHiiOWAREU80Av6foD45Yn7j43yHkHDt137mO4QyEUmiEZEkgBKwiIgfLlzhHle5X0rAIhIsGgGLiHiiZWgiIp5EkmfOXwlYRIJFUxAiIp7oJJyIiCcaAYuIeKI5YBERT7QKQkTEkyQaAYd8ByAikkguEom7FMfMMs1sppllmdkiMxsUra9nZu+Y2bLon3Wj9WZmI8xsuZl9aWa/ixWrErCIBEs4HH8pXj5wvXOuFdABGGhmrYCbgRnOuRbAjOh7gLOAFtEyAPhXrAaUgEUkWCIu/lIM51yec+6z6OttwGIgA+gNjI3uNhboE33dG3jOFfgvUMfMGhfXhhKwiARLJBJ3MbMBZja/SBmwr0OaWVOgDTAXaOicy4tuWgs0jL7OANYU+Vh2tG6/dBJORIKlBCfhnHMjgZHF7WNmNYBXgMHOua1mVvTzzswO+KyfErCIBEsCl6GZWRoFyXecc+7VaPU6M2vsnMuLTjGsj9bnAJlFPt4kWrdfgZiC6NqlE4sWfsjXWbO56caBXmPJfOBajvz0OY6Y/nix+1U9pjnHrniN2t1PLHWbKbVrcNgLQ2n5/lMc9sJQUmpVB6Bun1M54q0RHPH2CFq8eh9VWjYtdVulVblyZT6aPYX586az4PMZ3P73632HlBCjRj5EbvYXLPh8hu9QEqoifbfilqA5YCsY6j4DLHbOPVxk02TgkujrS4BJReovjq6G6ABsKTJVsU9Jn4BDoRAjHhtGz14XcvSxnenXrw8tW7bwFs/3/5nBykv+UfxOoRDpQy5l26zPS3TsGh2O4jcPDtqr/uCrz2PbR1+wuNNVbPvoCw6++jwAdq5Zx/K+Q1jS9VrWjphA5r3+v0A7d+6kS9e+tG3XhbbtutKlSyfat4+5WqfCe+65ifToeYHvMBKqon234uXyw3GXGDoCFwGnmdmCaOkODAfONLNlwBnR9wDTgJXAcmAUcHWsBpI+Abdv14YVK1azatW37N69m4kTJ3F2r67e4tnxySLCm7cXu89Bl/Zky5tzyN+wZc/6K8/h8MkPccRbI2h03flxt1n7zPZ8/8p7AHz/ynvU7nI8AD98+jXhrTsKXn+2hLTGDUrSlTKzY8cPAKSlpZKWlooLwCODZs2ey/ebNvsOI6Eq2ncrbolbBTHbOWfOuWOcc62jZZpzbqNz7nTnXAvn3BnOue+j+zvn3EDn3GHOuaOdc/NjhZr0CTg9oxFrsnML32fn5JGe3shjRMVLa1iP2l07sOH5N/eor3lyayo3TWfp2dez5KxBVD26OdXbHxnfMRvUIX/9JgDy128irUGdvfap1/9Mtr3/aanjT4RQKMS8T94mJ/sLZsyYxbx5JftNQMpHsn23CrlI/MWzAz4JZ2aXOedGJzKYX4OMO64gd/jYvR6dXfOUNtQ6uTVHTHsUgFD1qlRuls6OTxbR4vUHCFVKI1S9Kil1ahTukzt8LNs+3Dt5/fLneo0TjqZ+vzNZdu7Ne+3rQyQSoV37rtSuXYv/THyaI1sdwaKsYD68VTxIokuRS7MK4k5gnwk4upZuAICl1CYUql6KZoqXm7OWzCbphe+bZDQmN3dtmbVXWlWPaU7Tx28AIKVeLWp2Pg7yw2DGuidfZuOLb+/1mWV9bgQK5oDrnXc6397w2B7bd2/YTOrBdclfv6ngzw2bC7dV+W1TMu+7hpWX3El487ay69gB2LJlKx98MIcuXTspAVdAyfbd+plLogRc7BRE9HrmfZWv+N/i470450Y659o659qWZfIFmDd/Ac2bN6Np00zS0tLo27c3b0yZXqZtlsbik64gK1q2TJtD9t+fYsv0uWz74DPq9T2DULUqQMFURWr92nEdc+u7n1Dv3NMAqHfuaWx555OCY6Q3oNm/h/DNdY+wc1VucYcoNw0a1KN27VoAVKlShdNPP5klS5Z7jkr2Jdm+W4Xyw/EXz2KNgBsCXYFNv6g3YE6ZRFRC4XCYQYNvY9rUF0kJhRgzdgJZWUu9xXPIiBuoccJRpNatRav/PsvaR8ZjqSkAbBz31n4/t23WAio3z6TFa/cDEPnhJ74Z9DBs3LLfz/xs3ZOv0PTJm6jf70x25axn9dUFx2g0qD8pdWuSeddVQMHjupf28rvsq3GjhjzzzCOkpKQQChkvvzyFadOSf+nWC88/wamnnECDBvVYvXI+dw59kNFjXvIdVqlUtO9W3JJoBGzFnYE2s2eA0c652fvY9qJz7g+xGkitlJE8/zdKYH7j43yHkHDt137mO4QyEQnAKotfi/xdORZ7r+Jtu6pb3H/hNZ96q9TtlUaxI2Dn3OXFbIuZfEVEylsyLWvUpcgiEixJNAWhBCwiwaIELCLih8v3f4FFvJSARSRYkif/KgGLSLAk04UYSsAiEixKwCIinmgKQkTED01BiIh44vKVgEVE/NAUhIiIHxXgPutxUwIWkWBRAhYR8UMjYBERT1y+7wjipwQsIoGiEbCIiCdKwL8CbfMqxiPeE2njBS19h1AmWr2e5zuEhFu3Y7PvECou5/UhFyWiBCwigaIRsIiIJy6iEbCIiBeRsBKwiIgXmoIQEfFEUxAiIp4k0VPplYBFJFiSaQQc8h2AiEgiRcIWd4nFzJ41s/VmtrBI3T/MLMfMFkRL9yLbhpjZcjNbYmZdYx1fI2ARCZQEj4DHAP8EnvtF/SPOuQeLVphZK6A/cCSQDrxrZoc758L7O7hGwCISKM5Z3CX2sdyHwPdxNt0beMk5t9M5twpYDrQv7gNKwCISKC4SfzGzAWY2v0gZEGcz15jZl9EpirrRugxgTZF9sqN1+6UELCKBEnEWd3HOjXTOtS1SRsbRxL+Aw4DWQB7w0IHGqjlgEQmUeKYWSnd8t+7n12Y2CpgSfZsDZBbZtUm0br80AhaRQEnkKoh9MbPGRd6eA/y8QmIy0N/MKptZM6AF8Elxx9IIWEQCJZGrIMxsPNAJaGBm2cAdQCczaw04YDVwJYBzbpGZTQSygHxgYHErIEAJWEQCJpLAKQjn3Pn7qH6mmP2HAcPiPb4SsIgESlnPASdSIOaAu3bpxKKFH/J11mxuunGg73ASYtTIh8jN/oIFn8/wHQoAVf94AzUf+w817hq1nx2qU23QXdS489/UuPtp0k6KeRFQTFa9JtVuuI8aw8dQ7Yb7oFoNANI6nEaNoSOpcdcoqt/6GKHMQ0vdVkk99PhdfLH0Q2bMeb2wrtVRRzD57XG8+9FrjBn/BDVqVi/3uBItGb9bzsVffEv6BBwKhRjx2DB69rqQo4/tTL9+fWjZsoXvsErtuecm0qPnBb7DKLRr9tvseHjIfrdXPu1sIrnfsP2OK9lx3/VU6XclpMT3C1bKEcdS9fIb9z5m9/6Esz5n+82XEs76nCo9+gMQ2bCW7cP/yva/X8HOyS9Q9ZLrDqxTpTBx/OtccN6Ve9Q98NhQ7rnzEc7oeA5vTnmXP//lj+UeVyIl63erJMvQfIuZgM3st2Z2upnV+EV9t7ILK37t27VhxYrVrFr1Lbt372bixEmc3av0oy/fZs2ey/ebNvsOo1B46Ve47duK36lKtYI/K1fF7dgGkYLzD5W69aX67U9QY+hIKve5OO42U9ucyK6PpgOw66PppLbpWBDL8iz4YTsA+SsWE6p3UAl7U3pz53zK5k1b9qg7tPkh/HfOfABmvf8x3XudWe5xJVKyfrciEYu7+FZsAjaza4FJwF+AhWbWu8jme8oysHilZzRiTXZu4fvsnDzS0xt5jOjXaeeM10lp/BtqPjKBmneN4qcXnwTnSD3yOFIaZrBj6EC233ElKYccTsrhR8d1zFDturgtBVeBui3fE6pdd699Kp1yFvlfFbvSp9ws/Xo5XbufBkDP3l1Jz0juf4fJ+t1KphFwrN8RrwCOc85tN7OmwMtm1tQ59xiw3+ijl/MNALCU2oRCyT8XJsVLPaot4W9XsOP+GwgdnE71G+5j2+1fkXrUcaQedRw17nyqYMfKVQk1zCC89Cuq3/Y4lpYGlati1WsW7vPTf54mf+H8vRv5xaRdym+PpdLJ3dhxT/lPQezLX6/5O3cNH8LgG69i+psz2b17t++QfpWS6SRcrAQccs5tB3DOrTazThQk4UMoJgFHL+cbCZBaKaNMp7pzc9aS2SS98H2TjMbk5q4tyyZlHyqd1I2dU8cDEFmfS2TDWlIaZwLGzqnj2fX+1L0+s+PuvwAFc8CVTurCj888sMf2yJZNWO16uC3fY7XrEdm6uXBbqEkzql52PT88PAS3Y2uZ9askVixbxR/OLbiVwKGHHcLpXU71HFHpJOt3qyKMbOMVaw54XXTBMQDRZNwTaADE93tkGZs3fwHNmzejadNM0tLS6Nu3N29Mme47rF+dyMb1pLb6HQBWqw6hRplEvssjf+F80k7qBpWrFGyrUx+rWSeuY+Yv+JhKHbsAUKljF/I/n1NwjHoHU+2af/DjqOFE1hV7pWe5qt+gHgBmxqAbruT50RM8R1Q6yfrdciUovsUaAV9MwRUdhZxz+cDFZvbvMouqBMLhMIMG38a0qS+SEgoxZuwEsrKW+g6r1F54/glOPeUEGjSox+qV87lz6IOMHvOSt3iqXnkLqb89FqtRm5oPjeen18di0VUOu96fws43XqDq5TcWLlP76T+jcNu3kr/oU0Lpv6HGbY8D4H76kR9H3ovbtjlmmzunvkS1q28j7ZRuuA3r+eFfdwFQpfeFhGrUoupF1xYcMxxmx9DyXSL1xNMPcELHdtSrX4f5C2fw4PAnqF69Gpf+qWDd/rQp7zJh3GvlGlOiJet3KxxJnsVd5sp4MVxZT0FI4my8oKXvEMpEq9fzfIeQcOt2bPYdQpnI35VT6vmDWY3OizvnnLz2Za/zFboSTkQCxe3/9FSFowQsIoESSaLfuZWARSRQIhoBi4j4oSkIERFPwkrAIiJ+RHwHUAJKwCISKErAIiKeaA5YRMSTCnCXybgpAYtIoGgZmoiIJ8U+hriCUQIWkUCJmEbAIiJeJNGVyErAIhIsWoYmIuKJVkGIiHiiS5FFRDzRCFiSUsaEFb5DKBObvp3hO4SEa9isq+8QKizNAYuIeKJVECIinmgKQkTEk2Sagkie5zeLiMQhbPGXWMzsWTNbb2YLi9TVM7N3zGxZ9M+60XozsxFmttzMvjSz38U6vhKwiARKpAQlDmOAbr+ouxmY4ZxrAcyIvgc4C2gRLQOAf8U6uBKwiARKIhOwc+5D4PtfVPcGxkZfjwX6FKl/zhX4L1DHzBoXd3wlYBEJFFeCYmYDzGx+kTIgjiYaOufyoq/XAg2jrzOANUX2y47W7ZdOwolIoJRkFYRzbiQw8kDbcs45MzvglW8aAYtIoCR4Dnhf1v08tRD9c320PgfILLJfk2jdfikBi0ighEtQDtBk4JLo60uASUXqL46uhugAbCkyVbFPmoIQkUBJ5IUYZjYe6AQ0MLNs4A5gODDRzC4HvgH6RnefBnQHlgM/AJfFOr4SsIgESiIvxHDOnb+fTafvY18HDCzJ8ZWARSRQdC8IERFPIkmUgpWARSRQ9FRkERFPkulmPIFIwF27dOLhh4eSEgrx7Ojx3P/AE75DSoig9mvgNX/k0kv74Zxj0aIlXHXljezcuavc48hb9x233PUgGzdtwjDO630WF/Xts8c+z457manTZwIQDodZ+c0aZk19idq1ah5wu7t27WLIXQ+RtWQZdWrX4sGhQ8ho3JA5n3zGo0+NZvfufNLSUrl+4OUcf1zrUvSw5B5/8l66dOvMhu820vH4HgDcefff6HpWZ3bv2s2qVd9yzZ9vZuuWbeUaV0kk0+0ok34dcCgUYsRjw+jZ60KOPrYz/fr1oWXLFr7DKrWg9qtxekP+fPWlnHzS2bRv142UlBTO+79eXmJJTUnhxr9cweRxI3lx5CO89OoUVqz6Zo99/njBebwy9gleGfsEg6+6lLatj447+ebkrePSa27aq/7VKdOpVbMGb058lov69eHhJ58FoG6dWvzzvn/w2vP/Ytht1zNk6IOl72QJvTjuVf7vnD/uUff+ex/RsX0PTj6hFyuWr+a6668q97hKIoKLu/iW9Am4fbs2rFixmlWrvmX37t1MnDiJs3sl/+NagtovgNTUFKpWrUJKSgpVq1UhL2997A+VgYMa1KPVEc0BqF69Goceksm67zbud/9p735A9zNPLXz/xtvv0f9Pgzj3koHcef8IwuH4Zh/fm/UxvbufAUCXTicz99MFOOdoeXhzDj6oPgDNmx3CTzt3smtX+f5m8PFH89i0acsedTPfm13Yt/nzFpCe3qhcYyqpktwLwreYCdjM2ptZu+jrVmb2VzPrXvahxSc9oxFrsnML32fn5FX4fyDxCGq/8nLXMeLRUSxe8hErVs5l65ZtvDdjlu+wyMlbx+JlKzjmyCP2uf3Hn35i9n/nc2ankwBYsfpb3prxAc8/9RCvjH2CUCjElOhURSzrv9tIo4MbAAU/jGpUr8bmLVv32Oed92fT6ojmVKpUqRS9SrwLLjqPd9/5wHcYxSqHS5ETptg5YDO7g4J7XKaa2TvA8cBM4GYza+OcG1YOMUqA1KlTix49z+SoVqewefNWnh/3BP3692HCS697i+mHH37kulvv5m/XXkmN6tX3uc/7s+fS5phWhdMPc+cvIOvr5fS/fBAAO3fupF7dOgBcO2QoObnr2J2/m7x133HuJQVr8y/s25tzenSJGc/yld/w8JPPMvKRivX1+usNfyY/P5//TJjsO5RihSvE2DY+sU7CnQe0BipTcNu1Js65rWb2IDAX2Oe/kOgt3QYAWEptQqF9/6NOhNyctWQ2SS983ySjMbm5a8usvfIS1H517nwSq79Zw4YNBbdYnTzpbTp0+J23BLw7P5/Bt95Njy6dObNTx/3u9+aMD+h+RqfC9845zj7rDK77895Xm46493agYFR967CHGPPP+/fYfvBB9Vm7fgONDj6I/Pww23f8QJ3atQBYu/47Bt1yF/f8/QZ+U+Tv37fzL/g9Xc/qTJ+eF/sOJaaKMLKNV6wpiHznXNg59wOwwjm3FcA59yPF9NM5N9I519Y517Ysky/AvPkLaN68GU2bZpKWlkbfvr15Y8r0Mm2zPAS1X2uyc2nfrg1Vq1YBoFOnE1ny9QovsTjnuP3eRzn0kEwu6f/7/e63bfsO5n/+FZ1PPqGwrkPb1rzz/mw2btoMwJat28hduy6udjuf1IFJ094FYPr7szj+uGMxM7Zu287VN97B4Ksu43fHHHngHUuw0884mWsHX8Ef+l3Fjz/+5DucmJLpJFysEfAuM6sWTcDH/VxpZrWpID9owuEwgwbfxrSpL5ISCjFm7ASyspb6DqvUgtqv+fMW8Prrb/LRnCnk5+fzxRdZPPvseC+xfP7lIt54awYtDmtaOE0w6MpLyFv3HQD9zilYhjXjgzmc2P53VIv+0AA4rNkh/OWKixkw+FYiLkJaaiq3/vVq0hs13LuhX/h9z64MuesBzur7R2rXqskDdxY80Wb8K2+wJjuXp0a/yFOjXwRg5KPDqB+d2igPo559hI4nt6d+/bos/HoWw+95jMF/vYrKlSvx6qQxQMHf4fWDby+3mErKf1qNnxXcP2I/G80qO+d27qO+AdDYOfdVrAZSK2Uk0/+PX7UqqRXrhE+ibPp2hu8QEq5hs2CsiPml77ctK/Uq3kFN+8edcx5b/ZLXVcPFjoD3lXyj9RuADWUSkYhIKQTpJJyISFKpCHO78VICFpFASZ70qwQsIgGjEbCIiCcVYnlWnJSARSRQnEbAIiJ+aBWEiIgnmoIQEfEkUszFZRWNErCIBErypF8lYBEJGC1DExHxRKsgREQ8yVcCFhHxQyNgERFPtAxNRMST4u5xXtEoAYtIoGgVhCSln/J3+Q6hTBzcNPaTiJPNQVXr+A6hwtKlyCIiniRyBGxmq4FtQJiChxS3NbN6wASgKbAa6Ouc23Qgx4/1VGQRkaTinIu7xKmzc661c65t9P3NwAznXAtgRvT9AVECFpFAiZSgHKDewNjo67FAnwM9kBKwiASKK8F/ZjbAzOYXKQP2OhxMN7NPi2xr6JzLi75eCzQ80Fg1BywigVKSOWDn3EhgZDG7nOScyzGzg4F3zOzrX3zemdkBTzorAYtIoIRd4i7FcM7lRP9cb2avAe2BdWbW2DmXZ2aNgfUHenxNQYhIoJRkCqI4ZlbdzGr+/BroAiwEJgOXRHe7BJh0oLFqBCwigZLAG7I3BF4zMyjIlS86594ys3nARDO7HPgG6HugDSgBi0igJCr9OudWAsfuo34jcHoi2lACFpFA0aXIIiKeKAGLiHiSyFUQZU0JWEQCRTdkFxHxRPcDFhHxRHPAIiKeaAQsIuJJOImeCheIS5G7dunEooUf8nXWbG66caDvcBJG/aq4Hn/yXpaumsucT6YV1vU+5yzmzHuTjVuX0rrNUR6jO3CN0hvy3GtPMW32RKbOmsDFA/oD8Oioe5g0cxyTZo7jvU8nM2nmOM+R7l/EubiLb0k/Ag6FQox4bBjdup9PdnYe//14Gm9Mmc7ixct8h1Yq6lfFNn7cq4z69ws8NeqBwrrFWUu5+A9X88iIuz1GVjrhcD7D73iErC+XUL16NV6d8TwfvT+XwVfcUrjPzXcOZtvW7R6jLF4yrYIo8QjYzJ4ri0AOVPt2bVixYjWrVn3L7t27mThxEmf36uo7rFJTvyq2OR/NY9OmzXvULV2yguXLVvkJKEG+W7eRrC+XALBjxw+sWLqaho0P3mOfs3qfwZTX3vYRXlwCMwI2s8m/rAI6m1kdAOfc2WUUV9zSMxqxJju38H12Th7t27XxGFFiqF/iW0ZmY1odfQRffLqwsK7tCW3Y8N33fLNyjcfIipdMI+BYUxBNgCzgaQrucWFAW+Ch4j4UvXP8AABLqU0oVL30kYpIualWvSqPj76fe257iB3bdxTW9zynK1NfrbijX0jo3dDKXKwpiLbAp8CtwBbn3PvAj865D5xzH+zvQ865kc65ts65tmWdfHNz1pLZJL3wfZOMxuTmri3TNsuD+iW+pKam8Pjo+3nj5beYPnVmYX1KSgpdenRm6uvveIwutrCLxF18KzYBO+cizrlHgMuAW83sn1SwE3fz5i+gefNmNG2aSVpaGn379uaNKdN9h1Vq6pf4cs+jt7Ni6SpGP7XnSocTT23PyuWrWZd3wA+AKBeJuiF7eYgrmTrnsoH/M7MewNayDalkwuEwgwbfxrSpL5ISCjFm7ASyspb6DqvU1K+K7enRj9Dx5OOpX78uC5fMZviwx9i0aTP3PXgHDRrUY8IrT/PVl4s5r89lvkMtkeOOP5Y+/Xrw9aJlhUvNHh72JB+8+xE9zunClFcr/g9LVwFGtvGysr5qJLVShv8fM/KrVrNSVd8hJNxBVev4DqFMLP1uvpX2GIfUPybunPPNxi9L3V5pVKjpBBGR0tKlyCIinuhmPCIinoQjyTMHrAQsIoFSEVY3xEsJWEQCRXPAIiKeaA5YRMQTjYBFRDzRSTgREU80BSEi4ommIEREPEmm21EqAYtIoGgdsIiIJxoBi4h4Ekmi21EG4rH0IiI/c87FXWIxs25mtsTMlpvZzYmOVSNgEQmURK2CMLMU4AngTCAbmGdmk51zWQlpAI2ARSRgXAlKDO2B5c65lc65XcBLQO9ExlrmI+D8XTnldsd5MxvgnBtZXu2VlyD2K4h9gmD2K9n6VJKcU/QJ7lEji/Q1A1hTZFs2cHzpI/yfoI2AB8TeJSkFsV9B7BMEs19B7BOw5xPco6Vcf9AELQGLiCRKDpBZ5H2TaF3CKAGLiOzbPKCFmTUzs0pAf2ByIhsI2iqIpJmnKqEg9iuIfYJg9iuIfYrJOZdvZtcAbwMpwLPOuUWJbKPMH0svIiL7pikIERFPlIBFRDwJRAIu68sFfTCzZ81svZkt9B1LIplZppnNNLMsM1tkZoN8x1RaZlbFzD4xsy+ifbrTd0yJZGYpZva5mU3xHUvQJH0CLnK54FlAK+B8M2vlN6qEGAN08x1EGcgHrnfOtQI6AAMD8Pe1EzjNOXcs0BroZmYd/IaUUIOAxb6DCKKkT8CUw+WCPjjnPgS+9x1Hojnn8pxzn0Vfb6Pgi53hN6rScQW2R9+mRUsgzm6bWROgB/C071iCKAgJeF+XCyb1F/rXwsyaAm2AuZ5DKbXor+kLgPXAO865pO9T1KPATUDy3OMxiQQhAUsSMrMawCvAYOfcVt/xlJZzLuyca03B1VLtzewozyGVmpn1BNY75z71HUtQBSEBl/nlgpJYZpZGQfId55x71Xc8ieSc2wzMJBjz9x2Bs81sNQVTe6eZ2Qt+QwqWICTgMr9cUBLHzAx4BljsnHvYdzyJYGYHmVmd6OuqFNw/9muvQSWAc26Ic66Jc64pBd+r95xzF3oOK1CSPgE75/KBny8XXAxMTPTlgj6Y2XjgY+AIM8s2s8t9x5QgHYGLKBhNLYiW7r6DKqXGwEwz+5KCAcE7zjkt2ZKYdCmyiIgnST8CFhFJVkrAIiKeKAGLiHiiBCwi4okSsIiIJ0rAIiKeKAGLiHjy/8sd58jw5YArAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, stack_pred)\n",
    "\n",
    "sns.heatmap(cm,annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7104508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(stack_model, open(\"Model/Stack_model.sav\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ca6e2",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cbff338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 3s 31ms/step - loss: 3022.4969 - accuracy: 0.3739 - val_loss: 1.5167 - val_accuracy: 0.3902\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.5534 - accuracy: 0.3849 - val_loss: 1.4941 - val_accuracy: 0.3902\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.5252 - accuracy: 0.3840 - val_loss: 1.4752 - val_accuracy: 0.3902\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4730 - accuracy: 0.4048 - val_loss: 1.4590 - val_accuracy: 0.3902\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4652 - accuracy: 0.3987 - val_loss: 1.4477 - val_accuracy: 0.3902\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.4879 - accuracy: 0.3809 - val_loss: 1.4386 - val_accuracy: 0.3902\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4625 - accuracy: 0.3988 - val_loss: 1.4294 - val_accuracy: 0.3902\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.4366 - accuracy: 0.4011 - val_loss: 1.4228 - val_accuracy: 0.3902\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4495 - accuracy: 0.3897 - val_loss: 1.4168 - val_accuracy: 0.3902\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4294 - accuracy: 0.3854 - val_loss: 1.4116 - val_accuracy: 0.3902\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4349 - accuracy: 0.4023 - val_loss: 1.4074 - val_accuracy: 0.3902\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4270 - accuracy: 0.3840 - val_loss: 1.4032 - val_accuracy: 0.3902\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.4041 - accuracy: 0.4051 - val_loss: 1.4003 - val_accuracy: 0.3902\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4131 - accuracy: 0.3991 - val_loss: 1.3978 - val_accuracy: 0.3902\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.4055 - accuracy: 0.4063 - val_loss: 1.3949 - val_accuracy: 0.3902\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4181 - accuracy: 0.3839 - val_loss: 1.3908 - val_accuracy: 0.3902\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3869 - accuracy: 0.4059 - val_loss: 1.3886 - val_accuracy: 0.3902\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3910 - accuracy: 0.4138 - val_loss: 1.3861 - val_accuracy: 0.3902\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3912 - accuracy: 0.3975 - val_loss: 1.3865 - val_accuracy: 0.3902\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3977 - accuracy: 0.3885 - val_loss: 1.3829 - val_accuracy: 0.3902\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3878 - accuracy: 0.3992 - val_loss: 1.3806 - val_accuracy: 0.3902\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3975 - accuracy: 0.4028 - val_loss: 1.3792 - val_accuracy: 0.3902\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3763 - accuracy: 0.3938 - val_loss: 1.3787 - val_accuracy: 0.3902\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3893 - accuracy: 0.3966 - val_loss: 1.3764 - val_accuracy: 0.3902\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3908 - accuracy: 0.4060 - val_loss: 1.3754 - val_accuracy: 0.3902\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3912 - accuracy: 0.3852 - val_loss: 1.3740 - val_accuracy: 0.3902\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3883 - accuracy: 0.3848 - val_loss: 1.3729 - val_accuracy: 0.3902\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3798 - accuracy: 0.3984 - val_loss: 1.3720 - val_accuracy: 0.3902\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3545 - accuracy: 0.4127 - val_loss: 1.3715 - val_accuracy: 0.3902\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3839 - accuracy: 0.4045 - val_loss: 1.3702 - val_accuracy: 0.3902\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3758 - accuracy: 0.3916 - val_loss: 1.3694 - val_accuracy: 0.3902\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3819 - accuracy: 0.3851 - val_loss: 1.3692 - val_accuracy: 0.3902\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3813 - accuracy: 0.3871 - val_loss: 1.3681 - val_accuracy: 0.3902\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3846 - accuracy: 0.3919 - val_loss: 1.3676 - val_accuracy: 0.3902\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3534 - accuracy: 0.4017 - val_loss: 1.3685 - val_accuracy: 0.3902\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.4001 - accuracy: 0.3834 - val_loss: 1.3661 - val_accuracy: 0.3902\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.4061 - accuracy: 0.3842 - val_loss: 1.3659 - val_accuracy: 0.3902\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3523 - accuracy: 0.4012 - val_loss: 1.3671 - val_accuracy: 0.3902\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3655 - accuracy: 0.4081 - val_loss: 1.3646 - val_accuracy: 0.3902\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3665 - accuracy: 0.3898 - val_loss: 1.3644 - val_accuracy: 0.3902\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3839 - accuracy: 0.3898 - val_loss: 1.3658 - val_accuracy: 0.3902\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3819 - accuracy: 0.3853 - val_loss: 1.3636 - val_accuracy: 0.3902\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3810 - accuracy: 0.3915 - val_loss: 1.3640 - val_accuracy: 0.3902\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3802 - accuracy: 0.4102 - val_loss: 1.3624 - val_accuracy: 0.3902\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3739 - accuracy: 0.3779 - val_loss: 1.3623 - val_accuracy: 0.3902\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3889 - accuracy: 0.3944 - val_loss: 1.3626 - val_accuracy: 0.3902\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3591 - accuracy: 0.4020 - val_loss: 1.3614 - val_accuracy: 0.3902\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3694 - accuracy: 0.3875 - val_loss: 1.3612 - val_accuracy: 0.3902\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3761 - accuracy: 0.3925 - val_loss: 1.3609 - val_accuracy: 0.3902\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3732 - accuracy: 0.3858 - val_loss: 1.3606 - val_accuracy: 0.3902\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3857 - accuracy: 0.3752 - val_loss: 1.3613 - val_accuracy: 0.3902\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3714 - accuracy: 0.3911 - val_loss: 1.3604 - val_accuracy: 0.3902\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3319 - accuracy: 0.4126 - val_loss: 1.3616 - val_accuracy: 0.3902\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3773 - accuracy: 0.3956 - val_loss: 1.3595 - val_accuracy: 0.3902\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3869 - accuracy: 0.3806 - val_loss: 1.3593 - val_accuracy: 0.3902\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3503 - accuracy: 0.4069 - val_loss: 1.3595 - val_accuracy: 0.3902\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3706 - accuracy: 0.4034 - val_loss: 1.3588 - val_accuracy: 0.3902\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3611 - accuracy: 0.3993 - val_loss: 1.3585 - val_accuracy: 0.3902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3581 - accuracy: 0.3848 - val_loss: 1.3583 - val_accuracy: 0.3902\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3646 - accuracy: 0.4085 - val_loss: 1.3587 - val_accuracy: 0.3902\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3824 - accuracy: 0.3872 - val_loss: 1.3581 - val_accuracy: 0.3902\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3786 - accuracy: 0.3956 - val_loss: 1.3579 - val_accuracy: 0.3902\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3572 - accuracy: 0.4002 - val_loss: 1.3576 - val_accuracy: 0.3902\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3582 - accuracy: 0.4128 - val_loss: 1.3580 - val_accuracy: 0.3902\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3647 - accuracy: 0.3972 - val_loss: 1.3573 - val_accuracy: 0.3902\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3634 - accuracy: 0.4122 - val_loss: 1.3571 - val_accuracy: 0.3902\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3582 - accuracy: 0.3983 - val_loss: 1.3571 - val_accuracy: 0.3902\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3518 - accuracy: 0.3975 - val_loss: 1.3573 - val_accuracy: 0.3902\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3723 - accuracy: 0.3891 - val_loss: 1.3567 - val_accuracy: 0.3902\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3801 - accuracy: 0.3806 - val_loss: 1.3565 - val_accuracy: 0.3902\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3676 - accuracy: 0.3863 - val_loss: 1.3563 - val_accuracy: 0.3902\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3589 - accuracy: 0.3998 - val_loss: 1.3572 - val_accuracy: 0.3902\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3457 - accuracy: 0.3923 - val_loss: 1.3563 - val_accuracy: 0.3902\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3645 - accuracy: 0.3991 - val_loss: 1.3561 - val_accuracy: 0.3902\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3797 - accuracy: 0.3917 - val_loss: 1.3559 - val_accuracy: 0.3902\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3714 - accuracy: 0.3963 - val_loss: 1.3557 - val_accuracy: 0.3902\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3841 - accuracy: 0.3893 - val_loss: 1.3556 - val_accuracy: 0.3902\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3563 - accuracy: 0.3937 - val_loss: 1.3556 - val_accuracy: 0.3902\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3725 - accuracy: 0.3885 - val_loss: 1.3554 - val_accuracy: 0.3902\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3703 - accuracy: 0.3973 - val_loss: 1.3553 - val_accuracy: 0.3902\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3505 - accuracy: 0.4071 - val_loss: 1.3552 - val_accuracy: 0.3902\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3798 - accuracy: 0.3867 - val_loss: 1.3550 - val_accuracy: 0.3902\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3674 - accuracy: 0.3930 - val_loss: 1.3549 - val_accuracy: 0.3902\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3635 - accuracy: 0.3911 - val_loss: 1.3548 - val_accuracy: 0.3902\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3587 - accuracy: 0.4049 - val_loss: 1.3548 - val_accuracy: 0.3902\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3500 - accuracy: 0.3958 - val_loss: 1.3547 - val_accuracy: 0.3902\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3549 - accuracy: 0.3932 - val_loss: 1.3547 - val_accuracy: 0.3902\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3762 - accuracy: 0.3997 - val_loss: 1.3545 - val_accuracy: 0.3902\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3794 - accuracy: 0.3854 - val_loss: 1.3543 - val_accuracy: 0.3902\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3847 - accuracy: 0.3791 - val_loss: 1.3543 - val_accuracy: 0.3902\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 1.3711 - accuracy: 0.3924 - val_loss: 1.3542 - val_accuracy: 0.3902\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 1.3802 - accuracy: 0.3908 - val_loss: 1.3540 - val_accuracy: 0.3902\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3591 - accuracy: 0.4020 - val_loss: 1.3540 - val_accuracy: 0.3902\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3729 - accuracy: 0.3902 - val_loss: 1.3540 - val_accuracy: 0.3902\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3784 - accuracy: 0.3814 - val_loss: 1.3539 - val_accuracy: 0.3902\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3548 - accuracy: 0.4117 - val_loss: 1.3539 - val_accuracy: 0.3902\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3606 - accuracy: 0.3843 - val_loss: 1.3539 - val_accuracy: 0.3902\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3798 - accuracy: 0.3894 - val_loss: 1.3538 - val_accuracy: 0.3902\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3643 - accuracy: 0.3917 - val_loss: 1.3538 - val_accuracy: 0.3902\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3431 - accuracy: 0.3870 - val_loss: 1.3537 - val_accuracy: 0.3902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27fc63fb490>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64,input_dim = 4, activation='relu'))\n",
    "model.add(Dense(124,activation='relu'))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f598c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# preds = model.predict(X_test)\n",
    "# predicted = np.argmax(preds,axis=1)\n",
    "# predicted\n",
    "# # predicted = np.argmax(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ee2b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, LSTM\n",
    "# model2 = Sequential()\n",
    "\n",
    "# model2.add(LSTM(128,input_shape=X_train.shape,return_sequences=True,activation='relu'))\n",
    "# model2.add(Dropout(0.5))\n",
    "\n",
    "# model2.add(LSTM(128,activation='relu'))\n",
    "# model2.add(Dropout(0.5))\n",
    "\n",
    "# model2.add(Dense(6,activation='softmax'))\n",
    "# model2.add(Dropout(0.5))\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "# model.fit(X_train,y_train,epochs=100,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a7668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50384ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
